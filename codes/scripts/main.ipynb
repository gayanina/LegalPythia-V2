{"cells": [{"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from __future__ import unicode_literals\n", "from matplotlib import colors"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from nltk.util import pr"]}, {"cell_type": "markdown", "metadata": {}, "source": ["# \n # commented for local testing<br>\n", "# For Legal Pythia<br>\n", "# @author: SURYA L RAMESH<br>\n", "# First Created on Thu May 27 17:28:25 2021<br>\n", "\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["# \n\n\n\n\n\n\n SECTION 1. IMPORT ALL REQUIREMENTS\n\n\n\n\n\n\n # commented for local testing<br>\n", "# from __future__ import unicode_literals # moved to the top<br>\n", "import streamlit as st <br>\n", "import pandas as pd<br>\n", "import os<br>\n", "import torch<br>\n", "import time <br>\n", "import nltk<br>\n", "import spacy<br>\n", "import pdfplumber<br>\n", "import docx2txt<br>\n", "import matplotlib.pyplot as plt<br>\n", "import base64<br>\n", "from annotated_text import annotated_text<br>\n", "from torch.utils.data import Dataset, TensorDataset, DataLoader #SequentialSampler, RandomSampler<br>\n", "from torch.nn.utils.rnn import pad_sequence<br>\n", "from transformers import AlbertTokenizer<br>\n", "from transformers import AlbertForSequenceClassification, AdamW<br>\n", "nlp = spacy.load('en_core_web_sm') # large needed for word vectors <br>\n", "path = os.path.abspath(os.getcwd())<br>\n", "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")<br>\n", "print (\"\\n >>> device used: \",device)<br>\n", "print (\"\\n\")<br>\n", "device_type = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"<br>\n", "\n\n\n\n\n\n\n\n\n SECTION 2. THE MODEL \n\n\n\n\n\n\n\n\n'' # commented for local testing"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["model = AlbertForSequenceClassification.from_pretrained(\"albert-base-v2\", num_labels=3)\n", "model.to(device)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["param_optimizer = list(model.named_parameters())\n", "no_decay = ['bias', 'gamma', 'beta']\n", "optimizer_grouped_parameters = [\n", "    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n", "     'weight_decay_rate': 0.01},\n", "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n", "     'weight_decay_rate': 0.0}\n", "]"]}, {"cell_type": "markdown", "metadata": {}, "source": [" contains all of the hyperparemeter information for training loop "]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["optimizer = AdamW(optimizer_grouped_parameters, lr=2e-5, correct_bias=False)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["epoch_to_resume = 4\n", "path_to_model_saved = 'model_epoch{}.pt'.format( epoch_to_resume)\n", "if os.path.isfile(path_to_model_saved):\n", "    print(\"\\n >>> loading checkpoint '{}'\".format(path_to_model_saved))\n", "    checkpoint = torch.load(path_to_model_saved,map_location=torch.device('cpu'))\n", "    savd_epoch = checkpoint['epoch']\n", "    best_acc = checkpoint['best_acc']\n", "    model.load_state_dict(checkpoint['state_dict'])\n", "    optimizer.load_state_dict(checkpoint['optimizer'])\n", "    print(\"\\n >>> loaded checkpoint '{}' (epoch {})\"\n", "          .format(path_to_model_saved, checkpoint['epoch']))\n", "else:\n", "    print(\"\\n >>> no checkpoint found at '{}'\".format(path_to_model_saved))\n", "    \n", "    \n", "    \n", "# ''''''''''''''''''''''' SECTION 3. THE FUNCTIONS ''''''''''''''''''''''''''''' # commented for local testing\n", "       \n", "def calculate_similarity_percentage(file1, file2):\n", "    \n", "    # spaCy has support for word vectors whereas NLTK does not\n", "    \n", "    text1 = nlp(file1)\n", "    text2 = nlp(file2)   \n", "             \n", "    sim = text1.similarity(text2)\n", "    return sim"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class SNLIDataAlbertPredictor(Dataset):"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["  def __init__(self,input_df):\n", "    self.label_dict = {'entailment': 0, 'contradiction': 1, 'neutral': 2}\n", "    self.input_df = input_df\n", "    self.base_path = '/content/'\n", "    self.tokenizer = AlbertTokenizer.from_pretrained('albert-base-v2', do_lower_case=True)\n", "    self.input_data = None\n", "  \n", "    self.init_data()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["  def init_data(self):\n", "    \n", "    self.input_data = self.load_data(self.input_df)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["  def load_data(self, df):\n", "    token_ids = []\n", "    mask_ids = []\n", "    seg_ids = []\n", "    premise_list = df['premise'].to_list()\n", "    hypothesis_list = df['hypothesis'].to_list()\n", "  \n", "    for (premise, hypothesis) in zip(premise_list, hypothesis_list):\n", "      premise_id = self.tokenizer.encode(premise, add_special_tokens = False)\n", "      hypothesis_id = self.tokenizer.encode(hypothesis, add_special_tokens = False)\n", "      pair_token_ids = [self.tokenizer.cls_token_id] + premise_id + [self.tokenizer.sep_token_id] + hypothesis_id + [self.tokenizer.sep_token_id]\n", "      premise_len = len(premise_id)\n", "      hypothesis_len = len(hypothesis_id)\n", "      segment_ids = torch.tensor([0] * (premise_len + 2) + [1] * (hypothesis_len + 1))  # sentence 0 and sentence 1\n", "      attention_mask_ids = torch.tensor([1] * (premise_len + hypothesis_len + 3))  # mask padded values\n", "      token_ids.append(torch.tensor(pair_token_ids))\n", "      seg_ids.append(segment_ids)\n", "      mask_ids.append(attention_mask_ids)\n", "    \n", "    \n", "    token_ids = pad_sequence(token_ids, batch_first=True)\n", "    mask_ids = pad_sequence(mask_ids, batch_first=True)\n", "    seg_ids = pad_sequence(seg_ids, batch_first=True)\n", "   \n", "    dataset = TensorDataset(token_ids, mask_ids, seg_ids)\n", "    #print(len(dataset))\n", "    return dataset"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["  def get_data_loaders(self, batch_size=32, shuffle=True):\n", "    input_loader = DataLoader(\n", "      self.input_data,\n", "      shuffle=shuffle,\n", "      batch_size=batch_size\n", "    )\n", "    return input_loader"]}, {"cell_type": "markdown", "metadata": {}, "source": ["code for checking similarity and contradiction"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["     \n", "def check_similarity_contradiction(sentence1, sentence2):\n", "           \n", "       data_input = {'premise':[sentence1], 'hypothesis':[sentence2]}\n", "       df_input = pd.DataFrame(data_input, columns = ['premise','hypothesis'])\n", "       \n", "       input_dataset = SNLIDataAlbertPredictor(df_input)\n", "       input_loader = input_dataset.get_data_loaders(batch_size=1)\n", "       \n", "       (pair_token_ids, mask_ids, seg_ids) = next(iter(input_loader))\n", "       pair_token_ids = pair_token_ids.to(device)\n", "       mask_ids = mask_ids.to(device)\n", "       seg_ids = seg_ids.to(device)\n", "       result = model(pair_token_ids, \n", "                                     token_type_ids=seg_ids, \n", "                                     attention_mask=mask_ids)\n", "       prediction = result.logits #Predition in tensor Form\n", "       softmax =torch.log_softmax(prediction, dim=1)\n", "       pred =softmax.argmax(dim=1)\n", "       \n", "       target_map = {0: 'entailment',1:'contradiction',2:'neutral'}\n", "       \n", "       if device_type == \"cpu\":\n", "          outcome = target_map[pred.data.cpu().numpy()[0]]\n", "       else:\n", "           outcome = target_map[pred[0]]  # modified to get value from tensor\n", "       return  outcome "]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def styler(col):\n", "    # apply style to prediction column only \n", "    if col.name != 'prediction':\n", "        return [''] * len(col)\n", "    bg_map = []\n", "    \n", "    for x in col:\n", "        \n", "        if x[0] == 'contradiction' :\n", "                bg_map.append ('background-color:LightCoral')\n", "        elif x[0] == 'entailment' :\n", "                bg_map.append( 'background-color:LightGreen')\n", "        else:\n", "                bg_map.append('')\n", "    \n", "        \n", "    #print (bg_map)\n", "    return bg_map"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def pdf_to_text(file):\n", "    pdf = pdfplumber.open(file)\n", "    page = pdf.pages[0]\n", "    text = page.extract_text()\n", "    pdf.close()\n", "    return text.encode('utf8')\n", "                \n", "def doc_to_text(file):\n", "    text = docx2txt.process(file)\n", "    text = text.replace('\\n\\n',' ')\n", "    text = text.replace('  ',' ')\n", "    return text.encode('utf8')"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def visualise_ner(text):\n", "    tokens = []\n", "    doc=nlp(text)\n", "    for token in doc:\n", "        if (token.ent_type_ == \"PERSON\"):\n", "            tokens.append((token.text, \"PERSON\", \"#faa\"))\n", "        elif (token.ent_type_ == \"LOC\"):\n", "            tokens.append((token.text, \"LOC\", \"#fda\"))\n", "        elif (token.ent_type_ == \"GPE\"):\n", "            tokens.append((token.text, \"GPE\", \"#be2\"))\n", "        elif (token.ent_type_ == \"ORG\"):\n", "            tokens.append((token.text, \"ORG\", \"#0cf\"))\n", "        elif (token.ent_type_ == \"DATE\"):\n", "            tokens.append((token.text, \"DATE\", \"#fd1\"))\n", "        elif (token.ent_type_ == \"MONEY\"):\n", "            tokens.append((token.text, \"MONEY\", \"#f1d\"))    \n", "        else:\n", "            tokens.append(\" \" + token.text + \" \")\n", "    return tokens"]}, {"cell_type": "markdown", "metadata": {}, "source": ["def visualise_ner(file1, file2):<br>\n", "    text1 = nlp(file1)<br>\n", "    text2 = nlp(file2)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["    annotated_text(text1)<br>\n", "    annotated_text(text2)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    "]}, {"cell_type": "markdown", "metadata": {}, "source": ["# \n\n\n\n\n\n\n\n\n SECTION 4. THE MAIN APP CODE \n\n\n\n\n\n\n # commented for local testing<br>\n", "       <br>\n", "def main():<br>\n", "    header = st.container() # updated st.beta_container() to st.container()<br>\n", "    steps = st.container() # updated st.beta_container() to st.container()<br>\n", "    userinputfiles = st.container() # updated st.beta_container() to st.container()<br>\n", "    userchoice = st.container() # updated st.beta_container() to st.container()<br>\n", " <br>\n", "    # -- Default selector list<br>\n", "    selector_list = ['Similarity %','Similarity and Contradition detection', 'Visualise Entities']<br>\n", "    with header:<br>\n", "        st.image('/Users/gayanin/RA-Work/Legal Pythia/LegalPythia-V2/codes/res/header.jpeg')<br>\n", "        st.title(' Welcome to Legal Pythia Demo!')<br>\n", "        st.text(' Here you get to upload two text files and check for similarity or contradiction')<br>\n", "    # with steps:<br>\n", "    #     st.subheader('The Three Step Process:')<br>\n", "        <br>\n", "    #     st.markdown ('* ** Step 1:** Load document 1' )    <br>\n", "    #     st.markdown ('* ** Step 2:** Load document 2' )<br>\n", "    #     st.markdown ('* ** Step 3:** Choose Similarity %  or Similarity and Contradiction Detection or Visualisation')<br>\n", "        <br>\n", "    <br>\n", "    # with userchoice:<br>\n", "        # userchoice = st.radio(\"Choose your comparison method\",('Similarity % ','Similarity and Contradition detection', 'Visualise Entities'))<br>\n", "        # if userchoice == 'Similarity % ':<br>\n", "        #         st.write('You have selected Similarity.')<br>\n", "        # if userchoice == 'Similarity and Contradition detection':<br>\n", "        #     st.write('You have selected Similarity and Contradition detection.')<br>\n", "        # if userchoice == 'Visualise Entities':<br>\n", "        #         st.write('\\n You have selected Visualisation.')<br>\n", "        <br>\n", "        # selector = st.sidebar.selectbox('Selector', selector_list)<br>\n", "    with userinputfiles and userchoice:<br>\n", "       <br>\n", "        # sel_col, disp_col = st.sidebar.columns(2) # updated st.beta_columns() to st.columns()<br>\n", "        file1 = st.sidebar.file_uploader(\"Upload first document\", type = ['txt','pdf','docx'])<br>\n", "        file2 = st.sidebar.file_uploader(\"Upload second document\", type = ['txt','pdf','docx'])<br>\n", "        print(\"Document1...................................\",file1)<br>\n", "        print(\"Document2...............................\",file2)<br>\n", "        userchoice = st.sidebar.selectbox('Setect the feature function', selector_list)<br>\n", "        # st.write('You selected:', userchoice)<br>\n", "        # if file1 is not None:<br>\n", "        #     premise_text = file1.read()       <br>\n", "        #     premises = nltk.sent_tokenize(premise_text.decode('utf8')) # bytes to string<br>\n", "        # if file2 is not None:<br>\n", "        #     hypothesis_text = file2.read()           <br>\n", "        #     hypotheses = nltk.sent_tokenize(hypothesis_text.decode('utf8')) # bytes to string<br>\n", "        if file1 is not None:<br>\n", "            if 'pdf' in file1.name:<br>\n", "               premise_text = pdf_to_text(file1) <br>\n", "            elif 'doc' in file1.name:<br>\n", "               premise_text = doc_to_text(file1)  <br>\n", "            else:<br>\n", "                premise_text = file1.read()       <br>\n", "            premises = nltk.sent_tokenize(premise_text.decode('utf8')) # bytes to string<br>\n", "            <br>\n", "        if file2 is not None:<br>\n", "            if 'pdf' in file2.name:<br>\n", "               hypothesis_text = pdf_to_text(file2) <br>\n", "            elif '.doc' in file2.name:<br>\n", "               hypothesis_text = doc_to_text(file2) <br>\n", "            else:<br>\n", "                hypothesis_text = file2.read()             <br>\n", "            hypotheses = nltk.sent_tokenize(hypothesis_text.decode('utf8')) # bytes to string<br>\n", "        if(file1 is not None) and  (file2 is not None) and userchoice == 'Similarity %':                       <br>\n", "           sim = calculate_similarity_percentage(premise_text.decode('utf8'),hypothesis_text.decode('utf8'))<br>\n", "        #    st.write(sim)<br>\n", "           sim_percent = \"{:.0%}\".format(sim)<br>\n", "           st.write (\"\\n The similarity of two documents is \", sim_percent)<br>\n", "           sim_p = 1 - sim<br>\n", "           #draw a pie chart<br>\n", "           plot_labels = 'Similarity %', 'Contradiction %'<br>\n", "           plot_sizes = [sim, sim_p]<br>\n", "        #    explode = (0.1, 0) <br>\n", "           colours = ['#81ef7d','#ea696d']<br>\n", "    <br>\n", "           fig1, ax1 = plt.subplots()<br>\n", "           ax1.pie(plot_sizes, colors=colours, labels=plot_labels, autopct='%1.1f%%',<br>\n", "           shadow=True, startangle=90)<br>\n", "           ax1.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.<br>\n", "           st.pyplot(fig1, transparent=True)<br>\n", "           <br>\n", "        if(file1 is not None) and  (file2 is not None) and userchoice == 'Similarity and Contradition detection':         <br>\n", "            st.text('File upload successful!.')<br>\n", "            st.text('Checking for Similarity and Contradictions...')<br>\n", "            my_bar = st.progress(0)<br>\n", "            for percent_complete in range(100):<br>\n", "                time.sleep(0.1)<br>\n", "            my_bar.progress(percent_complete + 1)<br>\n", "            df_output = pd.DataFrame(columns = ['premise', 'hypothesis', 'prediction'])<br>\n", "                             <br>\n", "            row_count = 0<br>\n", "            <br>\n", "            # Add a placeholder for progress bar<br>\n", "            checking_text = st.empty()<br>\n", "            bar = st.progress(0)<br>\n", "                       <br>\n", "                      <br>\n", "            totalCount = len(premises)  * len(hypotheses)<br>\n", "            for premise in premises:<br>\n", "                for hypothesis in hypotheses:<br>\n", "                    outcome = check_similarity_contradiction(premise, hypothesis) <br>\n", "                    row = {'premise':premise, 'hypothesis':hypothesis,'prediction':[outcome]}<br>\n", "                    row_count = row_count + 1<br>\n", "                    df_output =  df_output.append( row , ignore_index=True)<br>\n", "                    print(\"Row = \", row)<br>\n", "                    <br>\n", "                     # Update the progress bar <br>\n", "                    checking_text.text(f'Processing Similarity and Contradiction Detection...  {row_count} of {totalCount}')<br>\n", "                    bar.progress((row_count/totalCount))<br>\n", "                    time.sleep(0.1)<br>\n", "               <br>\n", "            streamlit_df = pd.DataFrame(df_output)<br>\n", "            df_output.to_csv('predictions.csv')    <br>\n", "            st.dataframe(streamlit_df.style.apply(styler))<br>\n", "            <br>\n", "            @st.cache<br>\n", "            def convert_df_to_csv(df):<br>\n", "                # IMPORTANT: Cache the conversion to prevent computation on every rerun<br>\n", "                return df.to_csv().encode('utf-8')<br>\n", "            st.download_button(<br>\n", "                label=\"Download data as CSV\",<br>\n", "                data=convert_df_to_csv(streamlit_df),<br>\n", "                file_name='document_comparison.csv',<br>\n", "                mime='text/csv',<br>\n", "            )<br>\n", "        if(file1 is not None) and  (file2 is not None) and userchoice == 'Visualise Entities':         <br>\n", "            st.write('Document 1: \\n')<br>\n", "            premise_tokens = visualise_ner(premise_text.decode('utf8'))<br>\n", "            annotated_text(*premise_tokens)<br>\n", "            st.write('\\n')<br>\n", "            st.write('Document 2: \\n')<br>\n", "            hypothesis_tokens = visualise_ner(hypothesis_text.decode('utf8'))<br>\n", "            annotated_text(*hypothesis_tokens)<br>\n", "            st.write('\\n')<br>\n", "    <br>\n", "    if \"load_state\" not in st.session_state:<br>\n", "       st.session_state.load_state = False<br>\n", "timestr = time.strftime(\"%Y%m%d-%H%M%S\")<br>\n", "if __name__ == \"__main__\":<br>\n", "    main()"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}